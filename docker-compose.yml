version: '3.2'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: echo stat | nc localhost 2181
      interval: 10s
      timeout: 10s
      retries: 3

  kafka:
    image: confluentinc/cp-kafka:latest
    healthcheck:
      test: ["CMD", "nc", "-vz", "localhost", "9092"]
      interval: 2s
      timeout: 2s
      retries: 15
    depends_on:
      - zookeeper
    ports:
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      command: "bash -c 'echo Waiting for Kafka to be ready... && \
                             cub kafka-ready -b broker:9092 1 20 && \
                             kafka-topics --create --if-not-exists --zookeeper zookeeper:2181 --partitions 1 --replication-factor 1 --topic ballpoolevent"
  mongo:
    image: mongo
    container_name: mongo
    environment:
      MONGO_INITDB_DATABASE: local
      MONGO_INITDB_ROOT_USERNAME: local
      MONGO_INITDB_ROOT_PASSWORD: local
      MONGO_NON_ROOT_USERNAM: local
      MONGO_NON_ROOT_PASSWORD: local
    command: ["--bind_ip_all"]
    ports:
      - "27017:27017"
    volumes:
      - ./mongo-volume:/data/db

  event-producer-consumer:
    build: ./spring-kafka
    depends_on:
      kafka:
        condition: service_healthy
    mem_limit: 512m

  batch-aggregator:
    build:
      context: ./spark-agregator
      dockerfile: Dockerfile-batch
    depends_on:
      - mongo

  stream-aggregator:
    build:
      context: ./spark-agregator
      dockerfile: Dockerfile-stream
    depends_on:
      - mongo
